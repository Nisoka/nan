分类, 检测劣质答案
问题:
    问答网站, 一个重要的问题就是保证帖子的质量.例如stackoverflow 付出很大努力, 来让回答者尽量完善答案.
    如果在用户输入答案时, 即刻就知道答案是否够好, 或者还不够好, 进而激励用户投入更多精力撰写答案,进而提升整个问答网站的质量 效果.
    问题就是 判断是否是个好答案。

* 5.1 策略
  我们无法的到一个完美的解决方案, 并且对于答案的好坏分歧很大, 所以期望的效果也不会特别高.
  1 先从最简单的K近邻开始构建一个简单模型, 效果不好
  2 然后切换使用逻辑回归 在一个小部分数据上有较好预测.
  3 怎么选择最佳模型, 并应用到目标系统上.
  
  
* 5.2 如何区分
  1) 如何表示数据样本
  2) 分类器该采用哪种模型

** 5.2.1 调整样本
   数据就是答案文本, 标签是good or bad 二值数据.代表提问者是否接受这个答案.
   原始文本 并不会一个好的数据表示方式, 算法也不能处理,
   *特征提取*
   *我们要从原始数据 提取出数据特征 得到 特征数据.进而让学习算法学习.数据特征的提取需要思考多思考*
     

** 5.2.2 调整分类器
   对于分类器推荐 逻辑回归 决策树 SVM 朴素贝叶斯


* 5.3 获取数据   
** 5.3.1 将数据消减到可处理的程度
   获得的数据12G 太庞大, 可以通过选取 11年以后的问答进行分类. 越近预测效果越好.
   

** 5.3.2 对属性进行预选择和处理
   

** 5.3.3 定义什么是优质答案 -- good
   1 使用isAccept 作为标签
   2 把 > 0 的答案作为正例 < 0 的答案作为负例
   肯定使用第二个划分比较合理, 因为被接受的并不一定是很好的

* 5.4 第一个分类器
  使用简洁的最近邻开始
  不是基于模型的方法, 类似于遍历搜索方法.
  具有明显缺陷.

** 5.4.1 KNN 算法开始
   from sklearn import neighbors
   knn = neighbors.KNeighborsClassifier(n_neighbors=2)
   拟合数据集
   knn.fit(dataSet)
   测试
   knn.predict(entry)
   测试 的到的是属于各个分类的概率值.
   knn.predict_proba(entry)
     
** 5.4.2 特征工程
   给分类器提供什么特征？
   *什么是特征工程呢？ 就是从数据中获得一些能够用来描述 算法目标的属性.*
   seeds 中我们的算法目标是区分种子类别, 而区分种子类别 最好的属性 就是形状-饱满度等, 而这些并不是简单的长度等等 而是 一个生成出来的量, 所以需要特征工程, 
   从数据中抽取出来最好的可以描述问题区分数据的特征属性.
   
   这里只有text, 但是是原始数据对分类没什么作用, 必须通过特征工程, 特征抽取 抽取出特定有效的特征.
   1) 考虑帖子中的链接数, linkCount, 可能好的答案,都会附上一些引申知识连接, 能够稍微描述 答案好坏.
   *特征工程 实际就是 获得一个好特征*

** 5.4.3 训练分类器
   通过抽取每个帖子的 链接数 构建新特征linkCount, 添加到原来已经抽取的特征中, 得到新数据集.
   knn.fit() 训练分类器.
   
** 5.4.4 评估分类器性能
   必须清楚地知道我们要评估的是什么?
   简单的方法是计算测试数据集上的平均预测质量.0表示错误预测 1表示完美预测. 可以通过knn.score()
   我们不会只做一次, 使用sklearn.cross_validation 的 KFold来进行交叉验证.
   ....
   经过测试结果, 使用linkCount 的正确率只有49%, 还不如抛硬币, 说明链接数并不能反映帖子的质量, 
   linkCount这个特征不具有很好的区分性. 至少在KNN K = 5时. 需要找新特征.

** 5.4.5 设计更多的特征   
   超链接数 描述质量效果不好, 使用代码行数可能是个好选择, 代码行数 至少标志了帖子的作者对解答这个问题很感兴趣, 感觉感兴趣和质量成正比. 提取出来之后, 应该在统计帖子词语数目时去掉代码部分的词.
   ...
   通过linkCount numCodeLines numTextTokens 得到结果 58% 的正确率 至少有所提升, 正在朝着正确的方向前进.更多的特征会带来更高的正确性. 我们继续引入设计更多的特征 *注意 并不是特征越多越好, 而是 有效的特征越多越好*
   AvgSentLen
   AvgWordLen
   NumAllCaps
   NumExclams
   ...
   结果 57%的正确率 怎么还更低了. 这是因为没考虑KNN的距离计算 要无量纲问题, 不然有些特征数值范围很大,那么直接导致了 在分类器中错误的得到了相当大的距离数值, 而且将其他的小数据范围的权重压缩的很小了, 绝对不行.

* 5.5 怎样提升效果
  1) 提供更多数据
     也许数据不够多, 提供更多训练数据
  2) 考虑模型复杂度
     也许模型复杂度还不够, 或者太复杂了 尝试修改K值
  3) 修改特征空间
     特征集合并不好,
     1 特征处理
     2 设计新特征、删除无用特征
  4) 改变模型
     也许KNN 就是不适合这个问题 尝试使用别的分类器。
     当 多次修改原来分类器的复杂度, 并提供更复杂的特征空间, 依旧没有什么效果时, 尝试换个模型.
  在实际应用中, 尝尝会 循环的尝试上面的四个方法, 然后尝试搭配组合期望发现一个完美的配置. 
  但是这样做出正确的抉择之前这样一定会花费很长时间.
  更明智的做法是: 偏差-方差折中法,来查看问题原理, 进而找到问题.

** 5.5.1 偏差-方差 及其折中
   *高偏差*
   不能很好的拟合数据, 欠拟合, 整体上,模型偏离数据太远,偏差太高.
   *高方差*
   拟合的过分的好,过拟合, 对训练数据过分拟合, 使用别的数据训练得到的模型参数完全不一样, 认为这个模型对给定数据有一个过高的 方差, 
   大多数问题的模型 都是在这两个错误点之间, 理想情况 我们要 低偏差+低方差.但是显示情况是我们有时候怎么处理都得不到很好的结果时, 就要有所取舍.
   
** 5.5.2 解决高偏差
   高偏差的情况, 就是模型拟合度不够好,拟合参数复杂度还不够, 增加训练数据明显不会有什么帮助, 删除特征也没有帮助,可能是模型简单.
   1 增加更多的特征
   2 让模型更复杂
   3 尝试别的模型

** 5.5.3 解决高方差
   高方差的情况, 就是拟合过分, 我们的模型学习的太多了, 对未知数据适应度不好.
   1 使用更多数据
   2 降低模型复杂度
   3 删减特征
   4 正则化 乘法复杂度

** 5.5.4 识别 高偏差或者高方差
   1) 训练误差 和 测试误差 画出来
   2) 高偏差
      测试误差开始下降, 但后来持续在一个较高的位置, 随着数据集规模的增大, 训练误差会与测试误差较为接近.
   3) 高方差 
      训练误差 与 测试误差 存在较大差距.

   x-datasize, y-Error
   这种情况下, 5NN 近邻算法, 
   1 随着datasize 增大 训练误差 测试误差都没有什么提升
   2 测试误差 和 训练误差 一直相差较大
   说明 较高方差. 并且增加训练数据不会有什么帮助, 我们只能通过 增大K 或者 消减特征空间来降低模型复杂度了.
   a 消减特征空间 
     作用不明显
   b 增大K来降低模型复杂度, 
     稍微有了一些作用, 当K = 90 时, 会有一个比较低的测试误差, 但是这是牺牲了 实时性能作为代价的. 意味着 对一个新的帖子分类, 要找到90个最近邻的其他帖子.
     而且随着时间增加 帖子越来越多 实时性能会越来越差.
   
   此时我们有充足的理由 抛弃KNN方法. 或者 找到一个跨越性的特征.
   基于文本分类情景中 非常出色的一个分类器 -- 逻辑回归.

* 5.6 采用逻辑回归
  逻辑回归分类器 处理文本的分类任务时, 效果很好.

** 5.6.1 小例子和一点数学
   使用逻辑回归的效果.
** 5.6.2 在问答问题应用逻辑回归
   逻辑回归处理 含有大量噪声的数据.
   将KNN K=90作为标准, 比较下.KNN k=90 达到62.8%
   LogReg C=0.1 能够达到63%, 稍微有所提升.
   采用不同的正则化参数C 能够做出不同的正确率, 较小的C 代表较大的惩罚力度, 会使得模型尽量消除过拟合,简化过拟合.
   逻辑回归的偏差-方差图.
   模型具有高偏差, 测试和训练误差很接近, 但误差都比较大, 意味着欠拟合.
   欠拟合 是 对于训练 测试数据集效果差不多, 都不好.
   过拟合 是 对训练数据集效果很好, 测试数据集相当差.
   
   现在还是有着欠拟合问题, 
   欠拟合问题可能原因
   1 数据噪音过大.
   2 特征集合不是很合适.
   3 模型复杂度不够, 拟合能力不强.

* 5.7 观察正确率的背后: 准确率和召回率
  我们一直用正确率衡量结果, 但是实际上我们并不需要 正负都预测的很好, 只要一个方向预测的好我们的问题实际上就被解决了.
  例如:
  分类器 对bad 做出好的预测, 那么检测到bad之前不用反馈
  相反, 我们可以在用户输入回答过程中, 为用户提供一些有用的评论, 然后逐渐评测, 当用户的回答很好时, 就不提供新的评论, 并说它是个优质回答
  当我们想尽可能的预测正确, 对于预测准确数量权重不高, 就要使用正确率.
  相反当我们想尽可能的将好/坏的所有样本检测出来, 而检测为好的准确定倒是不太关注时, 就要使用召回率.
  
  怎么优化准确率?
  统计 TP FP FN等样本数量, 可以绘制出 召回率 - 准确率曲线  --- ROC曲线.
  我们想要的就是 尽可能的右上角的点.
  考虑good bad 两类答案的准确预测和召回预测得到两个图
  看到 优质答案的ROC曲线明显更靠近右上角.
  
  怎么找到最优的 准确率-召回率点.
  通过 sklearn.metrics import precision_recall_curve

* 5.8 为分类器瘦身
  每个特征的实际贡献是不一样的. 对于逻辑回归等加权分类器, 可以通过权重系数来获得某个特征的贡献.
  结果 linkCount NumExcalms 贡献最多. 而NumImages 基本可以忽略.直观上有图片 更会被评价为优质答案, 但是实际上回答很少有图片, 太过稀疏, 所以抛弃该特征, 效果差不多.
  

* 5.9 出货
  序列化 - 存储.
  反序列化 - 读取.

* 5.10 end
  针对一个噪音很大的数据集, 构建了一个 准确率不错的分类器,
  我们学习了:
  1 KNN logistic 的优缺点
  2 如何提取特征, 特征都是什么, 其实抽取特征也很轻松.
  3 分析怎么提升一个分类器性能的方法, 以及 偏差-方差 来识别是 过拟合 还是欠拟合, 进而挑选对应的处理方法.
  4 准确率 召回率 来作为问题目标, 

   
   
